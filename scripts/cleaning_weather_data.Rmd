---
title: "Cleaning Weather Data"
author: "Camila Vargas"
date: "8/3/2021"
output: html_document
---


## Set up

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(googledrive)
library(here)
library(data.table)
library(tidyverse)
library(readxl)
library(janitor)
library(lubridate)

## Sets R not to use scientific notations
options(scipen=999) 

# Create raw data folders - DO I NEED A IF STATEMENT???

if (!dir.exists(here::here("/raw_data"))){
  dir.create(paste0(getwd(),"/raw_data"))
}

## If necesary create a sub directory inside the raw_data. This will be the case for porject that will end up in more than one package.
dir.create(paste0(getwd(),"/raw_data/weather"))

```



## Download data files into local computer

In this case, the project has multiple types of data. Each type of data will be cleaned in its own Rmd and will become its own package. 
Make sure the file path on the code is updated to the correct folder. In this case we are working with the weather data, so data is saved inside the `weather` folder. Update folder name if you are downloading other type of data.

```{r download files}
# url of folder where the data lives
# Copy pasete the url of the folder where the data lives

folder_url <- "https://drive.google.com/drive/u/1/folders/12YcXFF5Dz11c29FtGtwZVCEwrgC4iVV4"

# list of files inside the folder
files <- drive_ls(as_id(folder_url))

## Download each file to local computer
purrr::walk2(
    map(files$id, as_id),
    paste0("raw_data/weather/", files$name),
    drive_download,
    overwrite = TRUE
  )

# Check all files where downloaded
# Count files inside the raw_data forder to make sure the number of files downloaded is what is expected.
raw_data_path <- paste0(getwd(), "/raw_data/weather")

length(list.files(raw_data_path))

```


## Functions and tables with files info
Creating a table with all of our files by type to use as an index to access each file.

```{r read data}

## List wit all csv files in raw data
all_csv <- tibble(list.files(raw_data_path, pattern = ".csv")) %>% 
  rename(file_name = 1) %>% 
  mutate(path = paste0(raw_data_path, "/", file_name),
         n = 1:n(),
         type = "weather") %>% 
  unite(obj_name, type, n, sep = "_", remove = FALSE)

## List with all xls files
all_xls <- tibble(list.files(raw_data_path, pattern = c("xls", "xlsx"))) %>% 
  rename(file_name = 1) %>% 
  mutate(path = paste0(raw_data_path, "/", file_name),
         n = 1:n(),
         type = "weather") %>% 
  unite(obj_name, type, n, sep = "_", remove = FALSE)


## function to read csv and clean names as we read the file
read_csv_clean <- function(dataset){
  
  read_csv(dataset) %>% 
    clean_names()
}

## Function to read each pp sheet
read_weather_excel <- function(sheet_name){
   
  read_excel(paste0(raw_data_path, "/2010_2016_Palmyra_Weather_Table.xlsx"), sheet = sheet_name, skip = 6) %>% 
  clean_names() %>% 
  filter(!batt_volt_avg %in% c("Volts", "Avg", NA)) %>% 
  select(1:last_col(2)) %>% 
  mutate(timestamp = as.numeric(timestamp),
         timestamp = as.POSIXct(timestamp*86400, origin = "1899-12-30", tz = "HAST"))
}

```

## Read files

### Annual Precipitation

```{r}
## Read in all csv
for (i in all_csv$n){
  
  assign(all_csv$obj_name[i], read_csv_clean(all_csv$path[i]))
}

## This csv file is a summary table with avarage pp for years 2002 to 2016. We can use it to check if this data matches the raw data. But we do not need this file for the weather package.
```

### Read Weather Tables
Timestamp every 15 min year round* for all weather data

*Some years have missing data. See below
```{r}
## Weather table (xls) - timestamp ever 15 min of pp register by day

## Read each sheet separately to be mak sure all data is being read correctly

w_2010 <- read_weather_excel("2010")

w_2011 <- read_weather_excel("2011")

w_2012 <- read_weather_excel("2012")

w_2013 <- read_weather_excel("2013")

w_2014 <- read_weather_excel("2014")

w_2015 <- read_weather_excel("2015")

w_2016 <- read_weather_excel("2016")


```


## QA/QC

For each day, starting at 00:00 and ending at 23:45 in an inclrease of every 15 min, we expect to have 96 meassurments daily.
(96 x 365 = 35040)

- Timestamps were correctly converted to the corresponding year-month-day hours:min
- 2010 starts on Oct 16 at 16:45 and has countinous data every 15 min until Dec 31 23:34 (7,317 observations)
- Years 2011, 2012 (leap), 2013 and 2014 have countinous data for every day of the year every 15 min. (35,040; 35,136)
- Year 2015 has continuos data from Jan 1 until Nov 23 19:15 and then Sporadic data collection through end of 2015 (battery going out)
- Year 2016 has Sporadic data collection at beginning of 2016 (battery going out) and data goes only until Sep 28 14:30

**Column names**
- Years 2010:2013 have same columns
- Years 2015:2016 have same columns
- Year 2014 has some similarities with 2010:2013 and some with 2015:2016




## Rename columns name
Standarize columns names throughtout the years and rename according to EDI standards.

```{r}

w_10_14 <- bind_rows(w_2010, w_2011, w_2012, w_2013, w_2014) %>% 
  rename(batt_avg = batt_volt_avg,
         bp_avg = bp_k_pa_avg,
         slr_avg = slr_w_avg,
         slr_tot = slrk_j_tot,
         wind_speed_avg = wind_speed_10,
         wind_speed_max = wind_speed_11,
         wind_speed_min = wind_speed_12)

w_15_16 <- bind_rows(w_2015, w_2016) %>% 
  rename(batt_avg = batt_volt_avg,
         bp_avg = bp_k_pa_avg,
         slr_avg = slr_w_avg,
         slr_tot = slrk_j_tot,
         wind_speed_avg = wind_speed_8,
         wind_speed_max = wind_speed_9,
         wind_speed_min = wind_speed_10)  


```


## Identify number of missing values per year
According to the metadata there are three ways missing values are presented: "serv.", "NAN" or NA

NA is an empty cell
**From the orriginal Excel**
NAN = Not A Number
serv. = Servicing logger (no data)

```{r}

# serv_10_14 <- w_10_14 %>% 
#   filter_at(vars(2:13), any_vars(. == "serv."))
# 
# serv_10_14 <- w_10_14 %>% 
  

```

## Combine all years into one datafram

```{r}
w_complete <- bind_rows(w_10_14, w_15_16) %>%
  mutate_at(2:13, as.numeric) %>% 
  mutate(year = year(timestamp),
         date = date(timestamp),
         time = format(timestamp, format = "%H:%M:%S")) %>% 
  select(year, date, time, everything(), -timestamp)

```

## Inspect

Check counts are as expected
```{r}
## counts Nas in each columns
freeR::complete(w_complete)
 ## counts entries for each year
table(w_complete$year)

range(w_complete$date)

range(w_complete$time)

str(w_complete)

```

Do NAs match with what expected?




## Read precipitation data
Daily rainfall

```{r}
## Check for sheets names
excel_sheets(all_xls$path[2])

pp_annual <- read_excel(all_xls$path[2], sheet = "Annual", skip = 2) %>% 
  clean_names()

pp_monthly <- read_excel(all_xls$path[2], sheet = "Monthly Input (mm)") %>% clean_names()

```


## Clean pp data
```{r}
## First clean-up
pp_annual_clean <- pp_annual%>% 
  rename(month = x1) %>% 
  filter(!month %in% c("Total", "AVG.", "Three rainiest days on record:", "40160", "39093", "41661", NA)) %>% 
  mutate(x1977 = as.numeric(x1977)) %>% 
  pivot_longer(3:24,
               names_to = "year",
               values_to = "rainfall") %>% 
  mutate(month = str_remove(month, "\\."),
         year = str_remove(year, "x"),
         year = as.numeric(year))

## QA - Some of the Avg column do not match to average calculated across year
test_avg <- pp_annual_clean %>% 
  group_by( month, avg) %>% 
  summarise(avg_test = mean(rainfall, na.rm = T)) %>% 
  mutate(check = avg - avg_test)

## Finalizing the clean up: Standarizing names and rounding numbers
pp_annual_final <- pp_annual_clean %>% 
  mutate(month = case_when(month == "Aug" ~ "August",
                           month == "Dec" ~ "December",
                           month == "Feb" ~ "February",
                           month == "Jan" ~ "January",
                           month == "Sept" ~ "September",
                           month == "Oct" ~ "October",
                           month == "Nov" ~ "November" ,
                           T ~ month),
         rainfall = round(rainfall, digits =  3)) %>% 
  select(year, month, rainfall) %>% 
  arrange(year)

```

## Clean monthly pp data
```{r}
headers <- c("day", "Jul-08", "Aug-08", "Sep-08", "Oct-08", "Nov-08", "Dec-08", "Jan-09", "Feb-09", "Mar-09", "Apr-09", "May-09", "Jun-09", "Jul-09", "Aug-09", "Sep-09", "Oct-09", "Nov-09", "Dec-09", "Jan-10", "Feb-10", "Mar-10", "Apr-10", "May-10", "Jun-10", "Jul-10", "Aug-10", "Sep-10", "Oct-10", "Nov-10", "Dec-10", "Jan-11", "Feb-11", "Mar-11", "Apr-11", "May-11", "Jun-11", "Jul-11", "Aug-11", "Sep-11", "Oct-11", "Nov-11", "Dec-11", "Jan-12", "Feb-12", "Mar-12", "Apr-12", "May-12", "Jun-12", "Jul-12", "Aug-12", "Sep-12", "Oct-12", "Nov-12", "Dec-12", "Jan-13", "Feb-13", "Mar-13", "Apr-13", "May-13", "Jun-13", "Jul-13", "Aug-13", "Sep-13", "Oct-13", "Nov-13", "Dec-13", "Jan-14", "Feb-14", "Mar-14", "Apr-14", "May-14", "Jun-14", "Jul-14", "Aug-14", "Sep-14", "Oct-14", "Nov-14", "Dec-14", "Jan-15", "Feb-15", "Mar-15", "Apr-15", "May-15", "Jun-15", "Jul-15", "Aug-15", "Sep-15", "Oct-15", "Nov-15", "Dec-15", "Jan-16", "Feb-16", "Mar-16", "Apr-16", "May-16", "Jun-16", "Jul-16", "Aug-16", "Sep-16", "Oct-16", "Nov-16", "Dec-16", "Jan-17", "Feb-17", "Mar-17", "Apr-17", "May-17", "Jun-17", "Jul-17", "Aug-17", "Sep-17", "Oct-17")

names(pp_monthly) <- headers

pp_monthly_clean <- pp_monthly %>% 
  pivot_longer(cols = 2:113,
               names_to = "month_year",
               values_to = "rainfall") %>% 
  filter(!day %in% c("Total inches", "Total mm")) %>% 
  separate(month_year, c("month", "yr"), sep = "-") %>% 
  mutate(century = 20,
         day = as.numeric(day)) %>% 
  unite(year, century, yr, sep = "") %>% 
  select(year, month, day, rainfall) %>% 
  arrange(year)

```

## Save data into local computer
```{r}
dir.create(path = paste0(getwd(),"/clean_data"))

write_csv(w_complete, paste0(getwd(),"/clean_data/2010_2016_palmyra_weather_table.csv"))

write_csv(pp_monthly_clean, paste0(getwd(), "/clean_data/2008_2017_palmyra_monthly_rainfall.csv"))

```



## Upload to dive
```{r}

## Finalized data forlder url
finalized_url <- "https://drive.google.com/drive/u/1/folders/1xAeDVipB1X18JKCebb6J09qcvUqjKOGp"

## Upload weather data
drive_upload(media = paste0(getwd(),"/clean_data/2010_2016_palmyra_weather_table.csv"),
             path = as_id(finalized_url),
             name = "2010_2016_palmyra_weather_table.csv",
             type = "csv")

## Uploaded susccesfully: need to ceck NaN. When saving csv they tun into NAs. Do we need to keep them as NaN?

## Upload rainfall table
drive_upload(media = paste0(getwd(),"/clean_data/2008_2017_palmyra_monthly_rainfall.csv"),
             path = as_id(finalized_url),
             name = "2008_2017_palmyra_monthly_rainfall.csv",
             type = "csv")

```


## Metadata



